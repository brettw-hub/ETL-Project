{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File Data/airlines.csv does not exist: 'Data/airlines.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7e8312e037e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mairline_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Data/airlines.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mairline_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mairline_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mairline_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File Data/airlines.csv does not exist: 'Data/airlines.csv'"
     ]
    }
   ],
   "source": [
    "airline_file = \"Data/airlines.csv\"\n",
    "airline_df = pd.read_csv(airline_file)\n",
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the names of columns and filtering columns we require\n",
    "airline_clean_df = airline_df[[\"Airline ID\", \"Name\", \"IATA\", \"ICAO\", \"Country\", \"Active\"]].copy()\n",
    "airline_clean_df = airline_clean_df.rename(columns = {\"Name\": \"Operator\"})\n",
    "airline_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the name of Airlines in the Airlines.csv\n",
    "airline_clean_df = airline_clean_df.replace({'Aeroflot Russian Airlines': 'Aeroflot',\n",
    "                                            'Avianca - Aerovias Nacionales de Colombia': 'Avianca',\n",
    "                                            'Private flight': 'Private'})\n",
    "airline_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_clean_df['Active'] = airline_clean_df['Active'].replace({'n': 'N'})\n",
    "airline_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the Operator names have been changed\n",
    "airline_clean_df.loc[airline_clean_df['Operator'] == 'Avianca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the names of Countries\n",
    "airline_clean_df = airline_clean_df.replace({'ALASKA': 'United States',\n",
    "                                                        'AVIANCA': 'Colombia',\n",
    "                                                        'Russia]]': 'Russia'\n",
    "                                                        })\n",
    "airline_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if the Country names have been changed\n",
    "airline_clean_df.loc[airline_clean_df['Country'] == 'ALASKA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Resetin the index for airline_clean_df\n",
    "# airline_clean_df = airline_clean_df.reset_index()\n",
    "# # airline_clean_df = airline_df[[\"Airline ID\", \"Name\", \"Country\", \"Active\"]]\n",
    "# airline_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_clean_df.loc[airline_clean_df['Operator'] == 'Aeroflot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airline_clean_df['Operator'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airline_clean_df['Operator'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_file = \"Data/Airline_crash_data.csv\"\n",
    "crash_df = pd.read_csv(crash_file)\n",
    "crash_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_clean_df = crash_df[[\"Date\", \"Year\", \"Location\", \"Operator\", \"Type\", \"Aboard\", \"Fatalities\", \"Summary\"]].copy()\n",
    "crash_clean_df[\"Date\"] = pd.to_datetime(crash_clean_df[\"Date\"])\n",
    "crash_clean_df = crash_clean_df[crash_clean_df[\"Date\"].dt.year >= 1970]\n",
    "\n",
    "crash_clean_df = crash_clean_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_clean_df[\"Fatalities_rate\"] = (crash_clean_df['Fatalities']/crash_clean_df['Aboard'])*100\n",
    "crash_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1970, 1979, 1989, 1999,2009]\n",
    "\n",
    "group_names = [\"70's\", \"80's\", \"90's\", \"00's\"]\n",
    "grouped_crash_clean_df = crash_clean_df.copy()\n",
    "grouped_crash_clean_df['Year'] = pd.cut(crash_clean_df['Year'], bins, labels=group_names, include_lowest=True)\n",
    "grouped_crash_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_crash_clean_df['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_crash_clean_df['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools import add_constant as add_constant\n",
    "grouped_crash_clean_constant = add_constant(grouped_crash_clean_df)\n",
    "grouped_crash_clean_constant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_crash_clean_constant.groupby('Year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_crash_clean_constant.plot(x=\"Year\",y=\"Fatalities\",kind=\"line\",figsize=(20,6))\n",
    "plt.title('Count of Fatalities for different decades')\n",
    "plt.xlabel('Decades')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('FatalityrateAcrossDecades.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1_df =grouped_crash_clean_constant.groupby('Year').mean()\n",
    "new1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1_df.plot(y=\"Fatalities_rate\",kind=\"line\",figsize=(20,6))\n",
    "plt.title('Fatality rate Frequency for different decades')\n",
    "plt.xlabel('Decades')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('FatalityrateAcrossDecades.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2_df= grouped_crash_clean_df.copy()\n",
    "new2_df.dropna(inplace=True)\n",
    "new2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new3_df= new2_df[\"Location\"].str.split(\",\",n=1, expand=True) \n",
    "\n",
    "new3_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2_df[\"City_crash\"] =new3_df[0]\n",
    "new2_df[\"Country_crash\"] =new3_df[1]\n",
    "new2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new4_df= new2_df[\"Country_crash\"].str.split(\",\",n=1, expand=True) \n",
    "new4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new4_df[0] =np.where(~new4_df[1].isnull(),new4_df[1],new4_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2_df[\"Country_crash\"] =new4_df[0]\n",
    "new2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrydecade_df =new2_df[['Year','Aboard','Fatalities','Fatalities_rate','City_crash','Country_crash']].groupby(['Country_crash','Year']).count()\n",
    "countrydecade_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # All the crashes with two or more collisions, still trying a way to separating the two operators\n",
    "# crash_clean_df[crash_clean_df['Operator'].str.contains('/', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting the resolve how to split the two collision rows\n",
    "# crash_clean_df['Operator', 'Type'] = crash_clean_df['Operator', 'Type'].str.split(\"/\") \n",
    "# crash_clean_df.explode('Operator', 'Type').reset_index(drop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_clean_df = crash_clean_df.assign(Operator=crash_clean_df.Operator.str.split('/'))\n",
    "# crash_clean_df.explode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_clean_df.iloc[80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming Airlines so they match with the two datasets\n",
    "crash_clean_df = crash_clean_df.replace({'United Air Lines': 'United Airlines',\n",
    "                                         'AVIANCA': 'Avianca',\n",
    "                                         'Varig': ' Varig Log',\n",
    "                                         'Compania Dominicana de Aviacion': 'Dominicana de Aviaci',\n",
    "                                         'Aviogenex (Yugoslavia)': 'Aviogenex',\n",
    "                                         'Stirling Airways': 'Stirling Airlines',\n",
    "                                         'Japan Air Lines': 'Japan Airlines',\n",
    "                                         'Cathay PacifiAirways': 'Cathay Pacific',\n",
    "                                         'British European Airways': 'British Airways',\n",
    "                                         'Spantax': 'Spantax S.A.',\n",
    "                                         'Eastern Air Lines': 'Balitmore Airways',\n",
    "                                         'Alia Royal Jordanian Airlines': ' Royal Jordanian',\n",
    "                                         'Libya Arab Airlines': ' Libyan Airlines',\n",
    "                                         'Turkish Airlines(THY)': 'Turkish Airlines',\n",
    "                                         'Martinair Holland NV': 'Martinair',\n",
    "                                         'Ceskoslevenske Aerolinie': 'Czech Airlines',\n",
    "                                         'Inex Adria Aviopromet': 'Adria Airways',\n",
    "                                         'TAP (Air Portugal)': 'TAP Portugal',\n",
    "                                         'Air India': 'Air India Limited',\n",
    "                                         'Loftledidir IcelandiAirlines': 'Icelandair',\n",
    "                                         'Iran National Airlines': 'Iran Air',\n",
    "                                         'Dan Air Services': 'Dan-Air London',\n",
    "                                         'Korean Airlines': ' Korean Air',\n",
    "                                         'Arrow Airways': 'Arrow Air',\n",
    "                                         'Mexicana': 'Mexicana de Aviaci',\n",
    "                                         'Thai Airways': 'Thai Airways International',\n",
    "                                         'Tajikistan Airlines': 'Tajikistan International Airlines',\n",
    "                                         'Cebu PacifiAir': ' Cebu Pacific',\n",
    "                                         'China Airlines (Taiwan)': 'China Airlines',\n",
    "                                         'EgyptAir': 'Egyptair',\n",
    "                                         'Scandinavian Airlines (SAS)': 'Scandinavian Airlines System',\n",
    "                                         'Flash Air': 'Flash Airlines',\n",
    "                                         'Subir (S7)': 'S7 Airlines',\n",
    "                                         'Pulkovo Airlines': 'Rossiya-Russian Airlines',\n",
    "                                         'TAM (Brazil)': 'TAM Brazilian Airlines',\n",
    "                                         'One-Two-Go Airlines': 'One Two Go Airlines',\n",
    "                                         'Philippine Air Lines': 'Philippine Airlines',\n",
    "                                         'Garuda Indonesia Airlines': 'Garuda Indonesia',\n",
    "                                         'LAN': 'LAN Airlines'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the index column\n",
    "crash_clean_df = crash_clean_df.drop(columns=['index'])\n",
    "crash_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the two tables together\n",
    "airline_crash_df = pd.merge(airline_clean_df, crash_clean_df, how='outer', on='Operator')\n",
    "airline_crash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the NaN values with more meaningful data\n",
    "airline_crash_df = airline_crash_df[airline_crash_df['ICAO'].notna()]\n",
    "airline_crash_df = airline_crash_df[airline_crash_df['Airline ID'].notna()]\n",
    "airline_crash_df = airline_crash_df[airline_crash_df['IATA'].notna()]\n",
    "# airline_crash_df = airline_crash_df[airline_crash_df['Year'].notna()]\n",
    "airline_crash_df[['Aboard', 'Fatalities']] = airline_crash_df[['Aboard', 'Fatalities']].fillna(0)\n",
    "airline_crash_df[['Date', 'Location', 'Type', 'Summary']] = airline_crash_df[['Date', 'Location', 'Type', 'Summary']].fillna('No Inccident Recorded')\n",
    "airline_crash_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_crash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see Airline values are entered \n",
    "airline_crash_df[airline_crash_df['Aboard'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_crash_df[airline_crash_df['Active'] == 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_crash_df[airline_crash_df['Date'] == 'No Inccident Recorded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of crashes per Operator Country\n",
    "airline_crash_df[\"Country\"].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of active operators\n",
    "airline_crash_df[\"Active\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operators with the most crashes\n",
    "airline_crash_df[\"Operator\"].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_clean_df[\"Fatalities_rate\"] = (crash_clean_df['Fatalities']/crash_clean_df['Aboard'])*100\n",
    "crash_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1970, 1979, 1989, 1999,2009]\n",
    "\n",
    "group_names = [\"70's\", \"80's\", \"90's\", \"00's\"]\n",
    "grouped_crash_clean_df = crash_clean_df.copy()\n",
    "grouped_crash_clean_df['Year'] = pd.cut(crash_clean_df['Year'], bins, labels=group_names, include_lowest=True)\n",
    "grouped_crash_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_crash_clean_df['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_crash_clean_df['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools import add_constant as add_constant\n",
    "grouped_crash_clean_constant = add_constant(grouped_crash_clean_df)\n",
    "grouped_crash_clean_constant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_crash_clean_constant.groupby('Year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_crash_clean_constant.plot(x=\"Year\",y=\"Fatalities\",kind=\"line\",figsize=(20,6))\n",
    "plt.title('Count of Fatalities for different decades')\n",
    "plt.xlabel('Decades')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('FatalityrateAcrossDecades.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1_df =grouped_crash_clean_constant.groupby('Year').mean()\n",
    "new1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new1_df.plot(y=\"Fatalities_rate\",kind=\"line\",figsize=(20,6))\n",
    "plt.title('Fatality rate Frequency for different decades')\n",
    "plt.xlabel('Decades')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('FatalityrateAcrossDecades.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2_df= grouped_crash_clean_df.copy()\n",
    "new2_df.dropna(inplace=True)\n",
    "new2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new3_df= new2_df[\"Location\"].str.split(\",\",n=1, expand=True) \n",
    "\n",
    "new3_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2_df[\"City_crash\"] =new3_df[0]\n",
    "new2_df[\"Country_crash\"] =new3_df[1]\n",
    "new2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new4_df= new2_df[\"Country_crash\"].str.split(\",\",n=1, expand=True) \n",
    "new4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new4_df[0] =np.where(~new4_df[1].isnull(),new4_df[1],new4_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2_df[\"Country_crash\"] =new4_df[0]\n",
    "new2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrydecade_df =new2_df[['Year','Aboard','Fatalities','Fatalities_rate','City_crash','Country_crash']].groupby(['Country_crash','Year']).count()\n",
    "countrydecade_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxcountry_crash_df = new2_df.value_counts(subset=['Country_crash'])\n",
    "maxcountry_crash_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxcountry_crash_df.columns=['Country_crash','count']\n",
    "topten=maxcountry_crash_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxcountry_crash_df.plot(x=\"Year\",y=\"Fatalities\",kind=\"line\",figsize=(20,6))(y=\"Country_crash\",y=\"Year\",kind=\"line\",figsize=(20,6))\n",
    "topten.plot(kind=\"bar\",figsize=(20,6))\n",
    "plt.title('Countries with max crashes reported')\n",
    "plt.xlabel('Crash site across Countries')\n",
    "plt.ylabel('Frequency of occurence')\n",
    "plt.savefig('FatalityrateAcrossCountries.png')\n",
    "plt.show()\n"
   ]
  }
 ]
}